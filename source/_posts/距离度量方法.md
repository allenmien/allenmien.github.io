---
title: 距离度量方法
---
# 距离度量方法

## 欧氏距离

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/63284363.jpg)

## 曼哈顿距离

顾名思义，在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是“曼哈顿距离”。曼哈顿距离也称为“城市街区距离”(City Block distance)。

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/57610462.jpg)

## 切比雪夫距离 

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/50955332.jpg)

## 闵可夫斯基距离

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/15465424.jpg)



## 标准化欧氏距离

 标准化欧氏距离是针对欧氏距离的缺点而作的一种改进。标准欧氏距离的思路：既然数据各维分量的分布不一样，那先将各个分量都“标准化”到均值、方差相等。假设样本集X的均值(mean)为m，标准差(standard deviation)为s，X的“标准化变量”表示为：

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/21073147.jpg)

## 马氏距离

马氏距离是基于样本分布的一种距离。物理意义就是在规范化的主成分空间中的欧氏距离。所谓规范化的主成分空间就是利用主成分分析对一些数据进行主成分分解。再对所有主成分分解轴做归一化，形成新的坐标轴。由这些坐标轴张成的空间就是规范化的主成分空间。

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/74192165.jpg)

定义：有M个样本向量X1~Xm，协方差矩阵记为S，均值记为向量μ，则其中样本向量X到μ的马氏距离表示为：

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/3898023.jpg)

欧式距离&马氏距离：

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/75224379.jpg)

马氏距离的特点：

- 量纲无关，排除变量之间的相关性的干扰；
- 马氏距离的计算是建立在总体样本的基础上的，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，除非这两个总体的协方差矩阵碰巧相同；
- 计算马氏距离过程中，要求总体样本数大于样本的维数，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况下，用欧式距离计算即可。

## 余弦距离

几何中，夹角余弦可用来衡量两个向量方向的差异；机器学习中，借用这一概念来衡量样本向量之间的差异。

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/28630560.jpg)

夹角余弦取值范围为[-1,1]。余弦越大表示两个向量的夹角越小，余弦越小表示两向量的夹角越大。当两个向量的方向重合时余弦取最大值1，当两个向量的方向完全相反余弦取最小值-1。

## 汉明距离

**定义**

两个等长字符串s1与s2的汉明距离为：将其中一个变为另外一个所需要作的最小字符替换次数。

**汉明重量**

是字符串相对于同样长度的零字符串的汉明距离，也就是说，它是字符串中非零的元素个数。

因此，如果向量空间中的元素a和b之间的汉明距离等于它们汉明重量的差a-b。

## 杰卡德距离

杰卡德相似系数(Jaccard similarity coefficient)：两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数。

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/87204442.jpg)

杰卡德距离(Jaccard Distance)：与杰卡德相似系数相反，用两个集合中不同元素占所有元素的比例。

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/68075464.jpg)

## 相关距离

相关系数：是衡量随机变量X与Y相关程度的一种方法，相关系数的取值范围是[-1,1]。相关系数的绝对值越大，则表明X与Y相关度越高。当X与Y线性相关时，相关系数取值为1（正线性相关）或-1（负线性相关）：

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/31652565.jpg)

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/11932958.jpg)

##  信息熵

 以上的距离度量方法度量的皆为两个样本（向量）之间的距离，而信息熵描述的是整个系统内部样本之间的一个距离，或者称之为系统内样本分布的集中程度（一致程度）、分散程度、混乱程度（不一致程度）。系统内样本分布越分散(或者说分布越平均)，信息熵就越大。分布越有序（或者说分布越集中），信息熵就越小。

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/81138915.jpg)

![](http://markdocpicture.oss-cn-hangzhou.aliyuncs.com/18-4-25/86498765.jpg)

